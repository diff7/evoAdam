{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe110fc0dd0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from logger import Logger\n",
    "\n",
    "from solver import Solver\n",
    "from crossngover import CrossN\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader.dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one, train_two = torch.utils.data.random_split(trainset, [40000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7fe0ec06a6a0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_one = torch.utils.data.DataLoader(train_one, batch_size=256,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe19fd2c278>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(params, net, device=0):\n",
    "    \n",
    "    mode = params['mode']\n",
    "    evo_step = int(params['evo_step'])\n",
    "    \n",
    "    experiment_note = ''\n",
    "    path = ''\n",
    "    for key in params:\n",
    "        experiment_note += key +'_'+ params[key]+'\\n'\n",
    "        path +=  '_'+ params[key]\n",
    "    \n",
    "\n",
    "    logger = Logger(path, experiment_note)\n",
    "    \n",
    "    print(logger.path)\n",
    "    print(experiment_note)\n",
    "\n",
    "    lr = 0.001\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    evo_optim = CrossN()\n",
    "\n",
    "    def validation(net, dataloader, device=0):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                images, labels = data\n",
    "                images = images.cuda(device)\n",
    "                labels = labels.cuda(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return 100.0 * correct / total\n",
    "\n",
    "    \n",
    "    solver = Solver(\n",
    "        net,\n",
    "        optimizer,\n",
    "        logger,\n",
    "        criterion,\n",
    "        validation,\n",
    "        evo_optim, \n",
    "        trainloader,\n",
    "        testloader,\n",
    "        testloader,  \n",
    "        epochs=30,\n",
    "        evo_step=evo_step,\n",
    "        child_count=20,\n",
    "        best_child_count=3,\n",
    "        mode=mode,\n",
    "        debug=True,\n",
    "        lr=lr,\n",
    "        device=device)\n",
    "\n",
    "    logger.add_post_result(f'start: {datetime.now()}')\n",
    "    solver.start()\n",
    "    logger.add_post_result(f'finish: {datetime.now()}')\n",
    "    torch.save(net.state_dict(), logger.path + '/model_last.chk')\n",
    "    logger.close()\n",
    "    \n",
    "    \n",
    "\n",
    "def train_three_types(model, TF, name):\n",
    "    modes = ['evo_only', 'gradient', 'evo_cross']\n",
    "    \n",
    "    evo_step = 10\n",
    "\n",
    "    for mode in modes: \n",
    "#         orig_stdout = sys.stdout\n",
    "#         f = open(f'outputs/{name}_{mode}.txt', 'w')\n",
    "#         sys.stdout = f\n",
    "\n",
    "        \n",
    "        params = {'net_name':name,\n",
    "             'preptrained':TF,\n",
    "             'mode':mode,\n",
    "             'evo_step':str(evo_step)}\n",
    "        temp_model = copy.deepcopy(model)\n",
    "        train_models(params, temp_model)\n",
    "#         sys.stdout = orig_stdout\n",
    "#         f.close()\n",
    "        torch.cuda.empty_cache()\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "num_ftrs = net.fc.in_features\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "        'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "net.classifier = nn.Linear(num_ftrs, len(classes))\n",
    "net.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = net.state_dict()\n",
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['conv1.weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_d = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'params': [140604486520696,\n",
       "    140604483471616,\n",
       "    140604483472624,\n",
       "    140604483472552,\n",
       "    140604483472696,\n",
       "    140604483470464,\n",
       "    140604483470320,\n",
       "    140604483469960,\n",
       "    140604483473344,\n",
       "    140604483729592,\n",
       "    140604483729952,\n",
       "    140604483729808,\n",
       "    140604486269400,\n",
       "    140604484021488,\n",
       "    140604484019904,\n",
       "    140604481841120,\n",
       "    140604484685112,\n",
       "    140604486250288,\n",
       "    140604481663192,\n",
       "    140604481663048,\n",
       "    140604481663552,\n",
       "    140604484265520,\n",
       "    140604483976864,\n",
       "    140604486539160,\n",
       "    140604481663984,\n",
       "    140604481664056,\n",
       "    140604481664200,\n",
       "    140604481664488,\n",
       "    140604481664416,\n",
       "    140604481664632,\n",
       "    140604481665568,\n",
       "    140604481665496,\n",
       "    140604481665712,\n",
       "    140604481666072,\n",
       "    140604481666000,\n",
       "    140604481666216,\n",
       "    140604481664992,\n",
       "    140604481664920,\n",
       "    140604481665136,\n",
       "    140604481666432,\n",
       "    140604481665424,\n",
       "    140604481666576,\n",
       "    140604481951784,\n",
       "    140604481951352,\n",
       "    140604481951712,\n",
       "    140604482821216,\n",
       "    140604482821576,\n",
       "    140604483757760,\n",
       "    140604480229312,\n",
       "    140604480226648,\n",
       "    140604480225856,\n",
       "    140604482821936,\n",
       "    140604482821360,\n",
       "    140604482818120,\n",
       "    140604480225424,\n",
       "    140604482822008,\n",
       "    140604483990008,\n",
       "    140604483993392,\n",
       "    140604483992816,\n",
       "    140604483990944,\n",
       "    140604486455728,\n",
       "    140604488255024,\n",
       "    140604481587744,\n",
       "    140604482971472]}]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "torch.Size([64, 3, 7, 7])\n",
      "layer1.0.conv1.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.0.conv2.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.1.conv1.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.1.conv2.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer2.0.conv1.weight\n",
      "torch.Size([128, 64, 3, 3])\n",
      "layer2.0.conv2.weight\n",
      "torch.Size([128, 128, 3, 3])\n",
      "layer2.1.conv1.weight\n",
      "torch.Size([128, 128, 3, 3])\n",
      "layer2.1.conv2.weight\n",
      "torch.Size([128, 128, 3, 3])\n",
      "layer3.0.conv1.weight\n",
      "torch.Size([256, 128, 3, 3])\n",
      "layer3.0.conv2.weight\n",
      "torch.Size([256, 256, 3, 3])\n",
      "layer3.1.conv1.weight\n",
      "torch.Size([256, 256, 3, 3])\n",
      "layer3.1.conv2.weight\n",
      "torch.Size([256, 256, 3, 3])\n",
      "layer4.0.conv1.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "layer4.0.conv2.weight\n",
      "torch.Size([512, 512, 3, 3])\n",
      "layer4.1.conv1.weight\n",
      "torch.Size([512, 512, 3, 3])\n",
      "layer4.1.conv2.weight\n",
      "torch.Size([512, 512, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for l in state:\n",
    "    if 'conv' in l.lower():\n",
    "        print(l)\n",
    "        print(state[l].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/2020-01-31/_resnet18_256_test_lr_F_evo_only_10_23:48\n",
      "net_name_resnet18_256_test_lr\n",
      "preptrained_F\n",
      "mode_evo_only\n",
      "evo_step_10\n",
      "\n",
      "Start training\n",
      "\n",
      "first test\n",
      "started score - 0.0\n",
      "Epoch: 0\t Iterations: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cuda(): argument 'device' (position 1) must be torch.device, not CrossEntropyLoss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-419222edf56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_three_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet18_256_test_lr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7bc71dae5e5b>\u001b[0m in \u001b[0;36mtrain_three_types\u001b[0;34m(model, TF, name)\u001b[0m\n\u001b[1;32m     80\u001b[0m              'evo_step':str(evo_step)}\n\u001b[1;32m     81\u001b[0m         \u001b[0mtemp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;31m#         sys.stdout = orig_stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#         f.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7bc71dae5e5b>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(params, net, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_post_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'start: {datetime.now()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_post_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'finish: {datetime.now()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_last.chk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/evoAdam/solver.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"best child - {best_child_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'evo_only'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0mbest_child_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_evolve_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Evolution accuracy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbest_child_score\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/evoAdam/solver.py\u001b[0m in \u001b[0;36mbatch_evolve_simple\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m#best_child = mutate_weights(best_child, self.lr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mbest_child\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mbest_child_score\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbc_loss_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_count\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7bc71dae5e5b>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(net, dataloader, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cuda(): argument 'device' (position 1) must be torch.device, not CrossEntropyLoss"
     ]
    }
   ],
   "source": [
    "train_three_types(net, 'F', 'resnet18_256_test_lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mobilenet from F:\n",
    "- Evo + Cross - \n",
    "- Evo Only - \n",
    "- Standard - \n",
    "\n",
    "resnet from F:\n",
    "- Evo + Cross  - \n",
    "- Evo Only - \n",
    "- Standard - \n",
    "\n",
    "mobilenet pretrained T:\n",
    "- Evo + Cross - \n",
    "- Evo Only  - \n",
    "- Standard - \n",
    "\n",
    "resnet pretrained T:\n",
    "- Evo + Cross  \n",
    "- Evo Only \n",
    "- Standard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_of_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-1d64ebfb75c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrad_of_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgrad_of_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_of_param' is not defined"
     ]
    }
   ],
   "source": [
    "grad_of_params = {}\n",
    "for name, parameter in net.named_parameters():\n",
    "    grad_of_param[name] = parameter.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1d3cb7e771e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loc' is not defined"
     ]
    }
   ],
   "source": [
    "torch.distributions.Uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.7645]], device='cuda:0')), ('linear.bias', tensor([0.8300], device='cuda:0')), ('linear_two.weight', tensor([[-0.2343],\n",
      "        [ 0.9186]], device='cuda:0')), ('linear_two.bias', tensor([-0.2191,  0.2018], device='cuda:0')), ('linear_one.weight', tensor([[-0.3443,  0.4153]], device='cuda:0')), ('linear_one.bias', tensor([0.6233], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "#from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "true_a, true_b = 1, 2\n",
    "y = true_a + true_b*x + 0.1*np.random.randn(100, 1)\n",
    "\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor) # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "def pr(m):\n",
    "    if 'Linear' == m.__class__.__name__:\n",
    "        print(m.weight.grad)\n",
    "\n",
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "        self.linear_two = nn.Linear(1, 2)\n",
    "        self.linear_one = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.linear_two(x)\n",
    "        x =  self.linear_one(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(y, yhat)\n",
    "        loss.backward()\n",
    "        #model.apply(pr)\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "    return train_step\n",
    "\n",
    "# Estimate a and b\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = ManualLinearRegression().to(device) # model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "n_epochs = 100\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "print(model.state_dict())\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        batch_losses.append(loss)\n",
    "    training_loss = np.mean(batch_losses)\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            model.eval()\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat).item()\n",
    "            val_losses.append(val_loss)\n",
    "        validation_loss = np.mean(val_losses)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "    #print(f\"[{epoch+1}] Training loss: {training_loss:.3f}\\t Validation loss: {validation_loss:.3f}\")\n",
    "\n",
    "#print(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro(m): \n",
    "    if 'Linear' == m.__class__.__name__:\n",
    "        u = torch.distributions.Uniform(0,1)\n",
    "        uni = u.sample(sample_shape=m.weight.grad.size()).cuda(0)\n",
    "        print(f'UNI:{uni}, GRAD:{m.weight.grad}')\n",
    "        print(f'PROD:{uni*m.weight.grad}')\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNI:tensor([[0.1352]], device='cuda:0'), GRAD:tensor([[-1.5181]], device='cuda:0')\n",
      "PROD:tensor([[-0.2053]], device='cuda:0')\n",
      "UNI:tensor([[0.9012],\n",
      "        [0.8918]], device='cuda:0'), GRAD:tensor([[ 0.2293],\n",
      "        [-0.7210]], device='cuda:0')\n",
      "PROD:tensor([[ 0.2067],\n",
      "        [-0.6430]], device='cuda:0')\n",
      "UNI:tensor([[0.1182, 0.4613]], device='cuda:0'), GRAD:tensor([[ 0.1151, -0.3553]], device='cuda:0')\n",
      "PROD:tensor([[ 0.0136, -0.1639]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManualLinearRegression(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       "  (linear_two): Linear(in_features=1, out_features=2, bias=True)\n",
       "  (linear_one): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(pro) #.linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManualLinearRegression(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       "  (linear_two): Linear(in_features=1, out_features=2, bias=True)\n",
       "  (linear_one): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = torch.distributions.Uniform(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0075)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "u = torch.distributions.Uniform(-1,1)\n",
    "u.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5364)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8230)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
